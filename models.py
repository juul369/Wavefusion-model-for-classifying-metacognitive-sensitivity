import torch.nn as nn
import torch
import copy
import torch.nn.functional as F

class attention1d(nn.Module):
    def __init__(self, in_planes, ratios, K, temperature, init_weight=True):
        super(attention1d, self).__init__()
        self.avgpool = nn.AdaptiveAvgPool1d(1)
        if in_planes!=3:
            hidden_planes = int(in_planes*ratios)+1
        else:
            hidden_planes = K
        self.fc1 = nn.Conv1d(in_planes, hidden_planes, 1, bias=True)
        print('Hidden planes:', hidden_planes)
        self.bn = nn.BatchNorm2d(hidden_planes)
        self.fc2 = nn.Conv1d(hidden_planes, K, 1, bias=True)
        self.temperature = temperature
        if init_weight:
            self._initialize_weights()
        self.sigmoid = nn.Sigmoid()


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv1d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            if isinstance(m ,nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

    def updata_temperature(self):
        if self.temperature!=1:
            self.temperature -=3
            print('Change temperature to:', str(self.temperature))


    def forward(self, x):
        x = self.avgpool(x)
        x = self.fc1(x)
        x = F.relu(x)
        x = self.fc2(x).view(x.size(0), -1)

        return  torch.sigmoid(x/self.temperature) # are the outputted attention weights (juul)

class Wave_Lead_Conv(nn.Module):
    """
    Wave_Lead_Conv is a convolution model designed to convolve over a single scaleogram,
    of shape (1,freq,time) generated by one EEG lead. this model is the portion of
    onv2d_by_Leads model without the last linear layer that combines the output for each
    lead.
    """
    def __init__(self):

        super(Wave_Lead_Conv, self).__init__()

        self.conv1 = nn.Conv2d(1, 16, kernel_size=(5, 4), stride=(2, 1), padding=(2, 1))
        self.dropout1 = nn.Dropout(p = 0.01)
        self.maxpool1 = nn.MaxPool2d(( 2, 2))
        self.bn1 = nn.BatchNorm2d(16)

        self.conv2 = nn.Conv2d(16, 16, ( 4, 2), stride=( 2, 1), padding=( 0, 0))
        self.dropout2 = nn.Dropout(p = 0.01)
        self.maxpool2 = nn.MaxPool2d(( 2, 2))
        self.bn2 = nn.BatchNorm2d(16)

        self.conv4 = nn.Conv2d(16, 32, ( 2, 1), stride=( 1, 1), padding=( 0, 0)) # kernel size 2x1 changed from 2,2 originally
        self.dropout3 = nn.Dropout(p = 0.01)
        self.bn4 = nn.BatchNorm2d(32)

    def forward(self, x):
        #import pdb; pdb.set_trace()
        x = self.conv1(x)
        x = self.dropout1(x)
        x = torch.relu(x)
        x = self.maxpool1(x)
        x = self.bn1(x)

        x = self.conv2(x)
        x = self.dropout2(x)
        x = torch.relu(x)
        x = self.maxpool2(x)
        x = self.bn2(x)

        x = self.conv4(x)
        x = self.dropout3(x)

        x = x.view(-1, 32)

        return x


class WaveFusion_Feature_Model(nn.Module):
    """
    Wave Fusion Model. Contains 61 Wave Lead Convs that convolves over each
    eeg Lead.
    """
    def __init__(self, temperature = 37.5, device = torch.device):
        super(WaveFusion_Feature_Model,self).__init__()
        self.leads = 32
        self.hz = 41
        self.window = 10
        self.out = 32 #hyperparameter
        self.device = device
        self.temperature = temperature
        self.Wave_Lead_Conv = AttrProxy(self, 'Wave_Lead_Conv')
        for i in range(self.leads):
            self.add_module('Wave_Lead_Conv' + str(i), Wave_Lead_Conv())

        self.attention = attention1d(in_planes=self.leads, ratios=0.25, K=self.leads,temperature=self.temperature)
        #self.dropout = nn.Dropout(0.9)
        self.bn1 = torch.nn.BatchNorm1d(self.leads*self.out)
        self.fc1 = nn.Linear(self.leads*self.out,128)
        self.head = nn.Sequential(
            nn.Linear(128, 128),
            nn.ReLU(inplace=True),
            nn.Linear(128, 32)
        )

    def forward(self, x):
        """
        feeds each eeg channel in x to a Wave_Lead_Conv
        x: a tensor of shape BatchSize x self.leads x 32 x 256
        returns:
        On training: a list of size (batchsize, num_lead) w/ each entry a [1,2] tensor of softmax probabilities for each class
        On eval: a tensor containing the class losses for each data in the batch
        """
        tmp = []
        preds = []
        bs = len(x[:,0,0,0])
        preds = torch.zeros((bs, self.leads, self.out)).to(self.device)

        for j in range(self.leads):
            #each lead to a wave_lead_conv. reshape to 1,1,32,250
            preds[:,j,:] = self.Wave_Lead_Conv.__getitem__(j)(x[:,j,:,:].view(bs,1, self.hz, self.window).clone())

        attention = self.attention(preds)
        attention = torch.reshape(attention, [x.size(0),self.leads,1])
        #preds.size: bsx17x32
        preds = attention * preds
        preds = preds.view(-1, self.leads*self.out) #BS*544
        preds = torch.relu(preds)
        preds = self.bn1(preds)
        preds = self.fc1(preds) # BS x 128
        preds = F.normalize(self.head(preds), dim=1)

        return preds

class AttrProxy(object):
   """indexes Wave_Lead_Conv models as Wave_Lead_Conv0, Wave_Lead_Conv1,...
   Wave_Lead_Conv63  in the Wave_Fusion_Model."""
   def __init__(self, module, prefix):
       """
       args:
           module: the Wave_Lead_Conv component to be named
           prefix: int
       """
       self.module = module
       self.prefix = prefix

   def __getitem__(self, i):
       """retrieves the ith Wave_Lead_Conv from Wave_Fusion_Model."""
       return getattr(self.module, self.prefix + str(i))


class WaveFusion_contrastive_classifier_Model(nn.Module):
    """
    Wave Fusion Model. Contains 61 Wave Lead Convs that convolves over each
    eeg Lead.
    """
    def __init__(self, device = torch.device, temperature = 37.5, drop_rate = 0.5):
        super(WaveFusion_contrastive_classifier_Model,self).__init__()
        self.leads = 32
        self.hz = 41
        self.window = 10
        self.out = 32
        self.device = device
        self.temperature = temperature
        self.drop_rate = drop_rate
        self.Wave_Lead_Conv = AttrProxy(self, 'Wave_Lead_Conv')
        for i in range(self.leads):
            self.add_module('Wave_Lead_Conv' + str(i), Wave_Lead_Conv())


        self.attention = attention1d(in_planes=self.leads, ratios=0.25, K=self.leads,temperature=self.temperature)
        self.dropout = nn.Dropout(p = self.drop_rate)
        self.bn1 = torch.nn.BatchNorm1d(self.leads*self.out)
        self.fc1 = nn.Linear(self.leads*self.out,128)
        self.classifier = nn.Linear(128,2)

    def load_weights(self, weight_dict):
        for k,v in zip( weight_dict.keys(), self.state_dict().keys()):
            if k in  self.state_dict().keys():
              self.state_dict()[v] = copy.deepcopy(weight_dict[k])

    def freeze_parameter_grad(self, feature_extracting):
        if feature_extracting:
            for j in range(self.leads):
                for param in self.Wave_Lead_Conv.__getitem__(j).parameters():
                    param.requires_grad = False
            for param in self.bn1.parameters():
                param.requires_grad = False
            for param in self.fc1.parameters():
                param.requires_grad = False
        else:
            for j in range(self.leads):
                for param in self.Wave_Lead_Conv.__getitem__(j).parameters():
                    param.requires_grad = True
            for param in self.attention.parameters():
                param.requires_grad = True

    def forward(self, x):
        """
        feeds each eeg channel in x to a Wave_Lead_Conv
        x: a tensor of shape BatchSize x self.leads x 32 x 256
        returns:
        On training: a list of size (batchsize, num_lead) w/ each entry a [1,2] tensor of softmax probabilities for each class
        On eval: a tensor containing the class losses for each data in the batch
        """
        tmp = []
        preds = []
        bs = len(x[:,0,0,0])
        preds = torch.zeros((bs, self.leads, self.out)).to(self.device)

        for j in range(self.leads):
            preds[:,j,:] = self.Wave_Lead_Conv.__getitem__(j)(x[:,j,:,:].view(bs,1, self.hz, self.window).clone())
            
        attention = self.attention(preds)
        attention = torch.reshape(attention, [x.size(0),self.leads,1])

        # THe whole NN, from input to classifier prediction output
        preds = attention * preds
        preds = preds.view(-1, self.leads*self.out) #BS*544
        preds = torch.relu(preds)
        preds = self.bn1(preds)
        preds = self.fc1(preds) # BS x 128
        preds = self.dropout(preds)
        preds = torch.relu(preds)
        preds = self.classifier(preds) # BS x 2
        #return scores
        return preds, attention